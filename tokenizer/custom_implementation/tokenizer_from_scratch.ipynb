{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = None\n",
    "tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang: en\n",
      "len(text) = 6423\n",
      "len(tokens) = 6423\n",
      "---------\n",
      "Lang: hi\n",
      "len(text) = 91330\n",
      "len(tokens) = 91330\n",
      "---------\n",
      "Lang: ka\n",
      "len(text) = 108961\n",
      "len(tokens) = 108961\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for lang in [\"en\", \"hi\", \"ka\"]:\n",
    "    try:\n",
    "        with open(f\"tok_corpus_{lang}.txt\", \"r\") as file:\n",
    "            text = file.read().strip()\n",
    "        assert text, \"Tokenization corpus file is empty\"\n",
    "    except FileNotFoundError:\n",
    "        print(\"Tokenization corpus file not found\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Lang: {lang}\")\n",
    "\n",
    "    text = text.encode(\"utf-8\")\n",
    "    print(f\"len(text) = {len(text)}\")\n",
    "    \n",
    "    print(f\"len(tokens) = {len(list(map(int, text)))}\")\n",
    "\n",
    "    tokens += list(map(int, text))\n",
    "\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 0 of 7936\n",
      "Merging 100 of 7936\n",
      "Merging 200 of 7936\n",
      "Merging 300 of 7936\n",
      "Merging 400 of 7936\n",
      "Merging 500 of 7936\n",
      "Merging 600 of 7936\n",
      "Merging 700 of 7936\n",
      "Merging 800 of 7936\n",
      "Merging 900 of 7936\n",
      "Merging 1000 of 7936\n",
      "Merging 1100 of 7936\n",
      "Merging 1200 of 7936\n",
      "Merging 1300 of 7936\n",
      "Merging 1400 of 7936\n",
      "Merging 1500 of 7936\n",
      "Merging 1600 of 7936\n",
      "Merging 1700 of 7936\n",
      "Merging 1800 of 7936\n",
      "Merging 1900 of 7936\n",
      "Merging 2000 of 7936\n",
      "Merging 2100 of 7936\n",
      "Merging 2200 of 7936\n",
      "Merging 2300 of 7936\n",
      "Merging 2400 of 7936\n",
      "Merging 2500 of 7936\n",
      "Merging 2600 of 7936\n",
      "Merging 2700 of 7936\n",
      "Merging 2800 of 7936\n",
      "Merging 2900 of 7936\n",
      "Merging 3000 of 7936\n",
      "Merging 3100 of 7936\n",
      "Merging 3200 of 7936\n",
      "Merging 3300 of 7936\n",
      "Merging 3400 of 7936\n",
      "Merging 3500 of 7936\n",
      "Merging 3600 of 7936\n",
      "Merging 3700 of 7936\n",
      "Merging 3800 of 7936\n",
      "Merging 3900 of 7936\n",
      "Merging 4000 of 7936\n",
      "Merging 4100 of 7936\n",
      "Merging 4200 of 7936\n",
      "Merging 4300 of 7936\n",
      "Merging 4400 of 7936\n",
      "Merging 4500 of 7936\n",
      "Merging 4600 of 7936\n",
      "Merging 4700 of 7936\n",
      "Merging 4800 of 7936\n",
      "Merging 4900 of 7936\n",
      "Merging 5000 of 7936\n",
      "Merging 5100 of 7936\n",
      "Merging 5200 of 7936\n",
      "Merging 5300 of 7936\n",
      "Merging 5400 of 7936\n",
      "Merging 5500 of 7936\n",
      "Merging 5600 of 7936\n",
      "Merging 5700 of 7936\n",
      "Merging 5800 of 7936\n",
      "Merging 5900 of 7936\n",
      "Merging 6000 of 7936\n",
      "Merging 6100 of 7936\n",
      "Merging 6200 of 7936\n",
      "Merging 6300 of 7936\n",
      "Merging 6400 of 7936\n",
      "Merging 6500 of 7936\n",
      "Merging 6600 of 7936\n",
      "Merging 6700 of 7936\n",
      "Merging 6800 of 7936\n",
      "Merging 6900 of 7936\n",
      "Merging 7000 of 7936\n",
      "Merging 7100 of 7936\n",
      "Merging 7200 of 7936\n",
      "Merging 7300 of 7936\n",
      "Merging 7400 of 7936\n",
      "Merging 7500 of 7936\n",
      "Merging 7600 of 7936\n",
      "Merging 7700 of 7936\n",
      "Merging 7800 of 7936\n",
      "Merging 7900 of 7936\n",
      "Merging complete..\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    freq = {}\n",
    "    for pair in zip(ids[:-1], ids[1:]):\n",
    "        freq[pair] = freq.get(pair, 0) + 1\n",
    "    return freq\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids\n",
    "\n",
    "vocab_size = 1024*8\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Merging {i} of {num_merges}\")\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = 256 + i\n",
    "    # print(f\"Merging {pair[0]} and {pair[1]} to {idx}\")\n",
    "    ids = merge(ids, pair, idx)\n",
    "    merges[pair] = idx\n",
    "\n",
    "print(\"Merging complete..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "def decode(ids):\n",
    "    text = b\"\".join([vocab[id] for id in ids])\n",
    "    text = text.decode(encoding=\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "def encode(text):\n",
    "    tokens = text.encode(\"utf-8\")\n",
    "    while len(tokens) >= 2:\n",
    "        stats = get_stats(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "        if not pair in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My name is Yaseen and I'm a Deep Learning Engineer\"\n",
    "\n",
    "len(text.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == decode(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert tuple keys to strings\n",
    "merges_serializable = {f\"{k[0]},{k[1]}\": v for k, v in merges.items()}\n",
    "\n",
    "with open(\"merges.json\", \"w\") as f:\n",
    "    json.dump(merges_serializable, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"merges.json\", \"r\") as f:\n",
    "    loaded_merges = json.load(f)\n",
    "\n",
    "# Convert string keys back to tuples\n",
    "merges_reloaded = {tuple(map(int, k.split(','))): v for k, v in loaded_merges.items()}\n",
    "\n",
    "# Verify that the reloaded merges match the original\n",
    "print(merges == merges_reloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
